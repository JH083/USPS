agent:
  agent:
    name: sac
    class: agents.sac.SACAgent
    params:
      obs_dim: ${env.obs_dim}
      action_dim: ${env.action_dim}
      action_range: ${env.action_range}
      device: ${device}
      critic_cfg: ${double_q_critic}
      actor_cfg: ${diag_gaussian_actor}
      discount: 0.99
      init_temperature: 0.1
      alpha_lr: ${sac_alpha_lr}
      alpha_betas:
      - 0.9
      - 0.999
      actor_lr: ${sac_actor_lr}
      actor_betas:
      - 0.9
      - 0.999
      actor_update_frequency: 1
      critic_lr: ${sac_critic_lr}
      critic_betas:
      - 0.9
      - 0.999
      critic_tau: 0.005
      critic_target_update_frequency: 2
      batch_size: 1024
      learnable_temperature: true
      robust_method: 'no'
      robust_coef: 0.1
  double_q_critic:
    class: agents.critic.DoubleQCritic
    params:
      obs_dim: ${agent.params.obs_dim}
      action_dim: ${agent.params.action_dim}
      hidden_dim: 1024
      hidden_depth: 2
  diag_gaussian_actor:
    class: agents.actor.DiagGaussianActor
    params:
      obs_dim: ${agent.params.obs_dim}
      action_dim: ${agent.params.action_dim}
      hidden_depth: 2
      hidden_dim: 1024
      log_std_bounds:
      - -5
      - 2
_group_:
  env:
    name: cartpole_swingup
    class: envs.rwrl_env.RWRLEnv
    params:
      domain_name: cartpole
      task_name: realworld_swingup
      task_kwargs:
        random: ${seed}
        perturb_spec:
          enable: false
          period: 1
          scheduler: uniform
  max_episode_steps: 1000
  num_random_steps: 5000.0
  num_train_steps: 1000000.0
  eval_frequency: 10000.0
  num_eval_episodes: 10
  sac_critic_lr: 0.0001
  sac_actor_lr: 0.0001
  sac_alpha_lr: 0.0001
  replay_buffer_capacity: ${num_train_steps}
seed: 1
device: cuda:0
log_frequency: 10000
log_save_tb: true
save_video: false
experiment: default
env:
  name: toy
root_dir: ./outputs
